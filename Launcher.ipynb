{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOcF8vFqJsWG66qWExKwcKx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Project Launcher"
      ],
      "metadata": {
        "id": "O65EaNA3KWoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import"
      ],
      "metadata": {
        "id": "7VH1sz0vKD2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ood-metrics\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "CAjEhUFVuOe8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading"
      ],
      "metadata": {
        "id": "yA4FrWqrKGpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/bred91/HamburgerManager.git\""
      ],
      "metadata": {
        "id": "iJlRtQDiuIlz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db1b4b1-32e6-4186-fdbc-0bb1ab445132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HamburgerManager'...\n",
            "remote: Enumerating objects: 67, done.\u001b[K\n",
            "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 67 (delta 30), reused 46 (delta 16), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (67/67), 21.48 MiB | 6.92 MiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "\n",
        "if not os.path.isfile('/content/Validation_Dataset.zip'):\n",
        "  !gdown --id 1r2eFANvSlcUjxcerjC8l6dRa0slowMpx\n",
        "  !jar xvf  \"/content/Validation_Dataset.zip\"\n",
        "\n",
        "clear_output()\n",
        "\n",
        "if not os.path.isdir('/content/Validation_Dataset'):\n",
        "  print(\"Dataset doesn't exist\")"
      ],
      "metadata": {
        "id": "70HelDlzFOCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/HamburgerManager/\")\n",
        "import HamburgerManager\n",
        "from HamburgerManager import *"
      ],
      "metadata": {
        "id": "IlywvhixokKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Test 1"
      ],
      "metadata": {
        "id": "FU18k_ePKOYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/HamburgerManager/eval/evalAnomaly.py --method MSP --withT 10.0 --isColab --input /content/Validation_Dataset/FS_LostFound_full/images --loadDir /content/HamburgerManager/trained_models/"
      ],
      "metadata": {
        "id": "aNt2Q2O8fmgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training"
      ],
      "metadata": {
        "id": "nzz3LaeThU-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets --upgrade\n",
        "!pip install segmentation-models-pytorch --upgrade\n",
        "!pip install torchmetrics --upgrade\n",
        "!pip install albumentations --upgrade\n",
        "!pip install loguru --upgrade\n",
        "!pip install tqdm --upgrade\n",
        "clear_output()\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2BMA-2qazYR",
        "outputId": "2660eb48-80e6-4a0f-beef-d0b8f690b9b7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "dataset_url = 'https://www.kaggle.com/kavithak1388/cityscapes'\n",
        "od.download(dataset_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCnqSbUra1Vg",
        "outputId": "6ce7d6fe-819d-4feb-8628-6e6f1e8adab4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: raffaelepane\n",
            "Your Kaggle Key: ··········\n",
            "Downloading cityscapes.zip to ./cityscapes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11.0G/11.0G [02:00<00:00, 98.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/zh320/realtime-semantic-segmentation-pytorch.git\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_OWqlX-hdYt",
        "outputId": "34f6728d-9608-4581-af38-8385b9bd1db6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'realtime-semantic-segmentation-pytorch'...\n",
            "remote: Enumerating objects: 449, done.\u001b[K\n",
            "remote: Counting objects: 100% (156/156), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 449 (delta 85), reused 120 (delta 68), pack-reused 293\u001b[K\n",
            "Receiving objects: 100% (449/449), 1015.67 MiB | 37.68 MiB/s, done.\n",
            "Resolving deltas: 100% (238/238), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/realtime-semantic-segmentation-pytorch/main.py"
      ],
      "metadata": {
        "id": "RUu5m5pej_Ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('save/best.pth')\n",
        "files.download('save/seg_trainer.log')"
      ],
      "metadata": {
        "id": "GCoY-P-UlCVL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}